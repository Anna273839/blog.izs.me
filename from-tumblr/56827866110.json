{
    "blog": {
        "description": "Writing and Stuff from Isaac Z. Schlueter",
        "name": "izs",
        "title": "blog.izs.me",
        "updated": 1544051896,
        "url": "http://blog.izs.me/",
        "uuid": "t:qZa3tMNNGjX7PQ45aXJ-jw"
    },
    "blog_name": "izs",
    "body": "<p>By <a href=\"https://twitter.com/maxogden/status/361995189205741568\">request</a></p>\n\n<p>The error code <code>EMFILE</code> means that a process is trying to open too many files.  Unix systems have a max number of file descriptors that may be assigned, also known as the <code>MAX_OPEN</code> value.  On OS X, the default is 256, which is pretty low for many modern programs that do a lot of file system writing and reading.</p>\n\n<p>This max value can be read or modified using the <code>ulimit -n</code> command.  Since I&rsquo;ve bumped up the MAX_OPEN ulimit value to <code>2560</code> on my system, here&rsquo;s what my laptop reports:</p>\n\n<pre><code>$ ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nfile size               (blocks, -f) unlimited\nmax locked memory       (kbytes, -l) unlimited\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 2560\npipe size            (512 bytes, -p) 1\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 709\nvirtual memory          (kbytes, -v) unlimited\n</code></pre>\n\n<p>These ulimit values are important!  You don&rsquo;t want runaway programs to accidentally open way too many files, and take up unnecessary resources on your program by accident.</p>\n\n<p><a href=\"https://npmjs.org/\">npm</a>, being a package manager, opens a lot of files, often more than 256 at a single time.  In order to get around this limitation, there are two options:</p>\n\n<ol><li>Always be very careful to not open too many files.</li>\n<li>Handle <code>EMFILE</code> errors by queuing the <code>open</code> operation, and then attempting it again once a file closes.</li>\n</ol><p>The only way to reliably do #2, however, is by monkey-patching Node&rsquo;s <code>fs</code> module, which is exactly what the <a href=\"https://npmjs.org/package/graceful-fs\">graceful-fs</a> module does.  A really interesting collision of bugs in npm, graceful-fs, and lockfile, led it to ignore certain open operations, and so you could easily get into cases where the script could not reasonably handle these problems.  Basically, it would open a lockfile to reserve a specific tar operation, and then not have any file descriptors left to actually <strong>do</strong> the tar unpack operation!  Also, graceful-fs was not actually monkey-patching with a queue, but instead trying to do some fancy clever back-off stuff, which just wasn&rsquo;t as solid.</p>\n\n<p>Graceful-fs 2.0 and lockfile 0.4 contain the fixes for their relevant parts of this flub up.  The latest version of npm 1.3 has all the fixes.</p>\n\n<p>At this point, no matter HOW small your <code>ulimit -n</code> value is, <code>graceful-fs</code> will prevent it from ever raising an <code>EMFILE</code> error.  Of course, it does this at the expense of making <code>open</code> operations potentially take longer.  I&rsquo;m planning on exploring using a slightly smarter monkey-patch, so that it only will enqueue open operations that have some kind of special flag or other opt-in switch.</p>",
    "can_like": false,
    "can_reblog": false,
    "can_reply": false,
    "can_send_in_message": true,
    "date": "2013-07-30 00:15:00 GMT",
    "display_avatar": true,
    "format": "markdown",
    "id": 56827866110,
    "is_blocks_post_format": false,
    "note_count": 14,
    "post_url": "http://blog.izs.me/post/56827866110/wtf-is-emfile-and-why-does-it-happen-to-me",
    "reblog": {
        "comment": "<p>By <a href=\"https://twitter.com/maxogden/status/361995189205741568\">request</a></p>\n\n<p>The error code <code>EMFILE</code> means that a process is trying to open too many files.  Unix systems have a max number of file descriptors that may be assigned, also known as the <code>MAX_OPEN</code> value.  On OS X, the default is 256, which is pretty low for many modern programs that do a lot of file system writing and reading.</p>\n\n<p>This max value can be read or modified using the <code>ulimit -n</code> command.  Since I\u2019ve bumped up the MAX_OPEN ulimit value to <code>2560</code> on my system, here\u2019s what my laptop reports:</p>\n\n<pre><code>$ ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nfile size               (blocks, -f) unlimited\nmax locked memory       (kbytes, -l) unlimited\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 2560\npipe size            (512 bytes, -p) 1\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 709\nvirtual memory          (kbytes, -v) unlimited\n</code></pre>\n\n<p>These ulimit values are important!  You don\u2019t want runaway programs to accidentally open way too many files, and take up unnecessary resources on your program by accident.</p>\n\n<p><a href=\"https://npmjs.org/\">npm</a>, being a package manager, opens a lot of files, often more than 256 at a single time.  In order to get around this limitation, there are two options:</p>\n\n<ol><li>Always be very careful to not open too many files.</li>\n<li>Handle <code>EMFILE</code> errors by queuing the <code>open</code> operation, and then attempting it again once a file closes.</li>\n</ol><p>The only way to reliably do #2, however, is by monkey-patching Node\u2019s <code>fs</code> module, which is exactly what the <a href=\"https://npmjs.org/package/graceful-fs\">graceful-fs</a> module does.  A really interesting collision of bugs in npm, graceful-fs, and lockfile, led it to ignore certain open operations, and so you could easily get into cases where the script could not reasonably handle these problems.  Basically, it would open a lockfile to reserve a specific tar operation, and then not have any file descriptors left to actually <strong>do</strong> the tar unpack operation!  Also, graceful-fs was not actually monkey-patching with a queue, but instead trying to do some fancy clever back-off stuff, which just wasn\u2019t as solid.</p>\n\n<p>Graceful-fs 2.0 and lockfile 0.4 contain the fixes for their relevant parts of this flub up.  The latest version of npm 1.3 has all the fixes.</p>\n\n<p>At this point, no matter HOW small your <code>ulimit -n</code> value is, <code>graceful-fs</code> will prevent it from ever raising an <code>EMFILE</code> error.  Of course, it does this at the expense of making <code>open</code> operations potentially take longer.  I\u2019m planning on exploring using a slightly smarter monkey-patch, so that it only will enqueue open operations that have some kind of special flag or other opt-in switch.</p>",
        "tree_html": ""
    },
    "reblog_key": "2MGZds2c",
    "recommended_color": null,
    "recommended_source": null,
    "short_url": "https://tmblr.co/Z7nwWyqxD6l_",
    "slug": "wtf-is-emfile-and-why-does-it-happen-to-me",
    "state": "published",
    "summary": "WTF is EMFILE and why does it happen to me",
    "tags": [],
    "timestamp": 1375143300,
    "title": "WTF is EMFILE and why does it happen to me",
    "trail": [
        {
            "blog": {
                "active": true,
                "can_be_followed": true,
                "name": "izs",
                "share_following": false,
                "share_likes": false,
                "theme": {
                    "avatar_shape": "square",
                    "background_color": "#444444",
                    "body_font": "Helvetica Neue",
                    "header_bounds": "978,2448,2355,0",
                    "header_focus_height": 1152,
                    "header_focus_width": 2048,
                    "header_full_height": 3264,
                    "header_full_width": 2448,
                    "header_image": "https://static.tumblr.com/d248e27715343669f06a3852fd2cda53/utow0jf/nwUnbvgl6/tumblr_static_d2yiqqjdv1w8gsw0s0g4goc0o.jpg",
                    "header_image_focused": "https://static.tumblr.com/d248e27715343669f06a3852fd2cda53/utow0jf/mA1nbvglg/tumblr_static_tumblr_static_d2yiqqjdv1w8gsw0s0g4goc0o_focused_v3.jpg",
                    "header_image_scaled": "https://static.tumblr.com/d248e27715343669f06a3852fd2cda53/utow0jf/nwUnbvgl6/tumblr_static_d2yiqqjdv1w8gsw0s0g4goc0o_2048_v2.jpg",
                    "header_stretch": true,
                    "link_color": "#FB4C16",
                    "show_avatar": true,
                    "show_description": true,
                    "show_header_image": true,
                    "show_title": true,
                    "title_color": "#fb4c16",
                    "title_font": "Gibson",
                    "title_font_weight": "regular"
                }
            },
            "content": "<p>By <a href=\"https://twitter.com/maxogden/status/361995189205741568\">request</a></p>\n\n<p>The error code <code>EMFILE</code> means that a process is trying to open too many files.  Unix systems have a max number of file descriptors that may be assigned, also known as the <code>MAX_OPEN</code> value.  On OS X, the default is 256, which is pretty low for many modern programs that do a lot of file system writing and reading.</p>\n\n<p>This max value can be read or modified using the <code>ulimit -n</code> command.  Since I&rsquo;ve bumped up the MAX_OPEN ulimit value to <code>2560</code> on my system, here&rsquo;s what my laptop reports:</p>\n\n<pre><code>$ ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nfile size               (blocks, -f) unlimited\nmax locked memory       (kbytes, -l) unlimited\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 2560\npipe size            (512 bytes, -p) 1\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 709\nvirtual memory          (kbytes, -v) unlimited\n</code></pre>\n\n<p>These ulimit values are important!  You don&rsquo;t want runaway programs to accidentally open way too many files, and take up unnecessary resources on your program by accident.</p>\n\n<p><a href=\"https://npmjs.org/\">npm</a>, being a package manager, opens a lot of files, often more than 256 at a single time.  In order to get around this limitation, there are two options:</p>\n\n<ol><li>Always be very careful to not open too many files.</li>\n<li>Handle <code>EMFILE</code> errors by queuing the <code>open</code> operation, and then attempting it again once a file closes.</li>\n</ol><p>The only way to reliably do #2, however, is by monkey-patching Node&rsquo;s <code>fs</code> module, which is exactly what the <a href=\"https://npmjs.org/package/graceful-fs\">graceful-fs</a> module does.  A really interesting collision of bugs in npm, graceful-fs, and lockfile, led it to ignore certain open operations, and so you could easily get into cases where the script could not reasonably handle these problems.  Basically, it would open a lockfile to reserve a specific tar operation, and then not have any file descriptors left to actually <strong>do</strong> the tar unpack operation!  Also, graceful-fs was not actually monkey-patching with a queue, but instead trying to do some fancy clever back-off stuff, which just wasn&rsquo;t as solid.</p>\n\n<p>Graceful-fs 2.0 and lockfile 0.4 contain the fixes for their relevant parts of this flub up.  The latest version of npm 1.3 has all the fixes.</p>\n\n<p>At this point, no matter HOW small your <code>ulimit -n</code> value is, <code>graceful-fs</code> will prevent it from ever raising an <code>EMFILE</code> error.  Of course, it does this at the expense of making <code>open</code> operations potentially take longer.  I&rsquo;m planning on exploring using a slightly smarter monkey-patch, so that it only will enqueue open operations that have some kind of special flag or other opt-in switch.</p>",
            "content_raw": "<p>By <a href=\"https://twitter.com/maxogden/status/361995189205741568\">request</a></p>\n\n<p>The error code <code>EMFILE</code> means that a process is trying to open too many files.  Unix systems have a max number of file descriptors that may be assigned, also known as the <code>MAX_OPEN</code> value.  On OS X, the default is 256, which is pretty low for many modern programs that do a lot of file system writing and reading.</p>\n\n<p>This max value can be read or modified using the <code>ulimit -n</code> command.  Since I\u2019ve bumped up the MAX_OPEN ulimit value to <code>2560</code> on my system, here\u2019s what my laptop reports:</p>\n\n<pre><code>$ ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nfile size               (blocks, -f) unlimited\nmax locked memory       (kbytes, -l) unlimited\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 2560\npipe size            (512 bytes, -p) 1\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 709\nvirtual memory          (kbytes, -v) unlimited\n</code></pre>\n\n<p>These ulimit values are important!  You don\u2019t want runaway programs to accidentally open way too many files, and take up unnecessary resources on your program by accident.</p>\n\n<p><a href=\"https://npmjs.org/\">npm</a>, being a package manager, opens a lot of files, often more than 256 at a single time.  In order to get around this limitation, there are two options:</p>\n\n<ol><li>Always be very careful to not open too many files.</li>\n<li>Handle <code>EMFILE</code> errors by queuing the <code>open</code> operation, and then attempting it again once a file closes.</li>\n</ol><p>The only way to reliably do #2, however, is by monkey-patching Node\u2019s <code>fs</code> module, which is exactly what the <a href=\"https://npmjs.org/package/graceful-fs\">graceful-fs</a> module does.  A really interesting collision of bugs in npm, graceful-fs, and lockfile, led it to ignore certain open operations, and so you could easily get into cases where the script could not reasonably handle these problems.  Basically, it would open a lockfile to reserve a specific tar operation, and then not have any file descriptors left to actually <strong>do</strong> the tar unpack operation!  Also, graceful-fs was not actually monkey-patching with a queue, but instead trying to do some fancy clever back-off stuff, which just wasn\u2019t as solid.</p>\n\n<p>Graceful-fs 2.0 and lockfile 0.4 contain the fixes for their relevant parts of this flub up.  The latest version of npm 1.3 has all the fixes.</p>\n\n<p>At this point, no matter HOW small your <code>ulimit -n</code> value is, <code>graceful-fs</code> will prevent it from ever raising an <code>EMFILE</code> error.  Of course, it does this at the expense of making <code>open</code> operations potentially take longer.  I\u2019m planning on exploring using a slightly smarter monkey-patch, so that it only will enqueue open operations that have some kind of special flag or other opt-in switch.</p>",
            "is_current_item": true,
            "is_root_item": true,
            "post": {
                "id": "56827866110"
            }
        }
    ],
    "type": "text"
}