{
    "blog": {
        "description": "Writing and Stuff from Isaac Z. Schlueter",
        "name": "izs",
        "title": "blog.izs.me",
        "updated": 1544051896,
        "url": "http://blog.izs.me/",
        "uuid": "t:qZa3tMNNGjX7PQ45aXJ-jw"
    },
    "blog_name": "izs",
    "body": "<p><a href=\"https://en.wikipedia.org/wiki/Newcomb%27s_paradox\">Newcomb&rsquo;s Problem</a>\nis a very divisive thought experiment in decision theory. The tl;dr version is:</p>\n\n<p>A supreme intelligence Omega comes down from the sky, and offers you\ntwo boxes, labeled A and B.  In box A, Omega has placed $1000.</p>\n\n<p>Omega makes a prediction about whether you will open only one box, or\nboth boxes.  If Omega predicts that you will open both boxes, then box\nB is empty.  If Omega predicts that you will open only one box, then\nOmega places $1000000 in box B.</p>\n\n<p>In over a million trials, Omega has never incorrectly predicted\nsomeone&rsquo;s decision.  (Supreme intelligence is supreme!)</p>\n\n<p>Omega places both boxes before you, and flies away to torment some\nother decision theorist.</p>\n\n<p>Do you open both boxes, or just box B?</p>\n\n<p>Well, you figure, Omega is gone now, its prediction already in the\npast.  At this point, if I open both boxes, then I&rsquo;ll get either $1000\nor $1001000.  If I open only box B, then I&rsquo;ll get either $0 or\n$1000000.  Regardless of Omega&rsquo;s prediction, I&rsquo;m always better off\nopening both boxes.</p>\n\n<p>So you open box B, and find it empty.</p>\n\n<p>You lament that Omega seemingly rewards &ldquo;improper&rdquo; decision theorists,\nand treat yourself to $1000 worth of whatever.  Since you&rsquo;re a\ndedicated rationalist, you probably make a bunch of sound investments\nwith it and end up doing ok anyway.</p>\n\n<p>Good for you.</p>\n\n<p>Another approach is to commit to opening only box B, and stick to that\ncommitment.  Decision theory be damned, I want a million bucks.\nBefore doing anything else, you set box A on fire, just to be sure.\nYou open box B, and get a million dollars.</p>\n\n<p>What use is a decision theory if it doesn&rsquo;t optimize outcomes?  That&rsquo;s\nnot to say that it&rsquo;s worthless to study the science of priors and\nstatistics and possible outcomes.  Certainly, in most situations, we\nare not dealing with supreme intelligences handing out money\ncapriciously.  But in the real world, there <em>are</em> occasionally\nsituations where the ends matter more than being theoretically\ncorrect.</p>\n\n<p>On the other hand, perhaps a purity of theoretical correctness is an\nimportant part of one&rsquo;s self-image.  Maybe it imparts emotional\nsatisfaction that a million dollars just can&rsquo;t buy.</p>\n\n<p>It&rsquo;s perfectly fine to be a two-boxer.  In a way, I respect it, like a\nmonk or an artist.  There&rsquo;s a beauty in that purity.</p>\n\n<p>But still.  Fuck that, I want the money.  I can be a monk later.</p>\n\n<hr><p>Most programming languages are to some extent art projects.  There&rsquo;s a\nlot of subjectivity to them.  They exist to seek a beautiful ideal.</p>\n\n<p>Most programming languages are also to some extent practical.  You can\ndo real stuff with them.  They exist to make stuff.</p>\n\n<p>The difference is, when tradeoffs must be made between &ldquo;beautiful\nideal&rdquo; and &ldquo;make stuff&rdquo;, what wins?</p>\n\n<p>If our ideal is in fact beautiful, and if we are skilled in our\npursuit of it, then one might expect that these trade-offs will be\ninfrequent.  The most beautiful programming language is the one that\nis the most pragmatic.</p>\n\n<p>But like boxes of money, programming languages do not exist in a\nvacuum.  We have imperfect vision, and may find ourselves heading down\na blind alley to explore what we hope will be beautiful.  In the\nmaking of things, we may find that it was a mistake, and that the only\nway out is to choose to either make the language more beautiful (and\nlose pragmatic value for its current users) or preserve pragmatic\nvalue (and give up on some potential beauty).</p>\n\n<p>Both choices are fraught with hazard.  The first can alienate the\ncommunity.  The second can lead to a mongrel language with warts and\nbad parts.</p>\n\n<p>Making software is the purpose of a programming language.  That is the\nwinning condition.  Valuing something other than that seems to me akin\nto opening both boxes, because decision theory said so.</p>\n\n<p>In box A, Omega has placed beauty.  In box B, Omega has placed\npragmatism and community, but only if Omega predicts that you will\nonly choose box B.  Omega has never been wrong.</p>\n\n<p>Make your choice.</p>\n\n<p>Except, in this version, you can open B, and get pragmatism and\ncommunity.  But once opened, if you choose A, then the community will\neventually be lost.</p>\n\n<p>I can see the value in a beautiful thing.  But for myself,\nwilly-nilly, I like useful software and happy communities more than\nprogramming languages for their own sake.</p>\n\n<p>This is why I love JavaScript so much.  Fuck beautiful code, I wanna\nmake a web page.  We&rsquo;d rather lack a feature than add something\nthat&rsquo;ll break anything.  We drag the albatross of ancient websites\nalong with us, and while this is often a curse, it is also a sort of\nblessing.</p>\n\n<p>JavaScript is a one-boxer language.</p>",
    "can_like": false,
    "can_reblog": false,
    "can_reply": false,
    "can_send_in_message": true,
    "date": "2016-09-08 18:06:57 GMT",
    "display_avatar": true,
    "format": "markdown",
    "id": 150129331398,
    "is_blocks_post_format": false,
    "note_count": 8,
    "post_url": "http://blog.izs.me/post/150129331398/newcomb-programming-languages",
    "reblog": {
        "comment": "<p><a href=\"https://en.wikipedia.org/wiki/Newcomb%27s_paradox\">Newcomb\u2019s Problem</a>\nis a very divisive thought experiment in decision theory. The tl;dr version is:</p>\n\n<p>A supreme intelligence Omega comes down from the sky, and offers you\ntwo boxes, labeled A and B.  In box A, Omega has placed $1000.</p>\n\n<p>Omega makes a prediction about whether you will open only one box, or\nboth boxes.  If Omega predicts that you will open both boxes, then box\nB is empty.  If Omega predicts that you will open only one box, then\nOmega places $1000000 in box B.</p>\n\n<p>In over a million trials, Omega has never incorrectly predicted\nsomeone\u2019s decision.  (Supreme intelligence is supreme!)</p>\n\n<p>Omega places both boxes before you, and flies away to torment some\nother decision theorist.</p>\n\n<p>Do you open both boxes, or just box B?</p>\n\n<p>Well, you figure, Omega is gone now, its prediction already in the\npast.  At this point, if I open both boxes, then I\u2019ll get either $1000\nor $1001000.  If I open only box B, then I\u2019ll get either $0 or\n$1000000.  Regardless of Omega\u2019s prediction, I\u2019m always better off\nopening both boxes.</p>\n\n<p>So you open box B, and find it empty.</p>\n\n<p>You lament that Omega seemingly rewards \u201cimproper\u201d decision theorists,\nand treat yourself to $1000 worth of whatever.  Since you\u2019re a\ndedicated rationalist, you probably make a bunch of sound investments\nwith it and end up doing ok anyway.</p>\n\n<p>Good for you.</p>\n\n<p>Another approach is to commit to opening only box B, and stick to that\ncommitment.  Decision theory be damned, I want a million bucks.\nBefore doing anything else, you set box A on fire, just to be sure.\nYou open box B, and get a million dollars.</p>\n\n<p>What use is a decision theory if it doesn\u2019t optimize outcomes?  That\u2019s\nnot to say that it\u2019s worthless to study the science of priors and\nstatistics and possible outcomes.  Certainly, in most situations, we\nare not dealing with supreme intelligences handing out money\ncapriciously.  But in the real world, there <em>are</em> occasionally\nsituations where the ends matter more than being theoretically\ncorrect.</p>\n\n<p>On the other hand, perhaps a purity of theoretical correctness is an\nimportant part of one\u2019s self-image.  Maybe it imparts emotional\nsatisfaction that a million dollars just can\u2019t buy.</p>\n\n<p>It\u2019s perfectly fine to be a two-boxer.  In a way, I respect it, like a\nmonk or an artist.  There\u2019s a beauty in that purity.</p>\n\n<p>But still.  Fuck that, I want the money.  I can be a monk later.</p>\n\n<hr><p>Most programming languages are to some extent art projects.  There\u2019s a\nlot of subjectivity to them.  They exist to seek a beautiful ideal.</p>\n\n<p>Most programming languages are also to some extent practical.  You can\ndo real stuff with them.  They exist to make stuff.</p>\n\n<p>The difference is, when tradeoffs must be made between \u201cbeautiful\nideal\u201d and \u201cmake stuff\u201d, what wins?</p>\n\n<p>If our ideal is in fact beautiful, and if we are skilled in our\npursuit of it, then one might expect that these trade-offs will be\ninfrequent.  The most beautiful programming language is the one that\nis the most pragmatic.</p>\n\n<p>But like boxes of money, programming languages do not exist in a\nvacuum.  We have imperfect vision, and may find ourselves heading down\na blind alley to explore what we hope will be beautiful.  In the\nmaking of things, we may find that it was a mistake, and that the only\nway out is to choose to either make the language more beautiful (and\nlose pragmatic value for its current users) or preserve pragmatic\nvalue (and give up on some potential beauty).</p>\n\n<p>Both choices are fraught with hazard.  The first can alienate the\ncommunity.  The second can lead to a mongrel language with warts and\nbad parts.</p>\n\n<p>Making software is the purpose of a programming language.  That is the\nwinning condition.  Valuing something other than that seems to me akin\nto opening both boxes, because decision theory said so.</p>\n\n<p>In box A, Omega has placed beauty.  In box B, Omega has placed\npragmatism and community, but only if Omega predicts that you will\nonly choose box B.  Omega has never been wrong.</p>\n\n<p>Make your choice.</p>\n\n<p>Except, in this version, you can open B, and get pragmatism and\ncommunity.  But once opened, if you choose A, then the community will\neventually be lost.</p>\n\n<p>I can see the value in a beautiful thing.  But for myself,\nwilly-nilly, I like useful software and happy communities more than\nprogramming languages for their own sake.</p>\n\n<p>This is why I love JavaScript so much.  Fuck beautiful code, I wanna\nmake a web page.  We\u2019d rather lack a feature than add something\nthat\u2019ll break anything.  We drag the albatross of ancient websites\nalong with us, and while this is often a curse, it is also a sort of\nblessing.</p>\n\n<p>JavaScript is a one-boxer language.</p>",
        "tree_html": ""
    },
    "reblog_key": "8za5AaNp",
    "recommended_color": null,
    "recommended_source": null,
    "short_url": "https://tmblr.co/Z7nwWy2BqPyp6",
    "slug": "newcomb-programming-languages",
    "state": "published",
    "summary": "Newcomb Programming Languages",
    "tags": [],
    "timestamp": 1473358017,
    "title": "Newcomb Programming Languages",
    "trail": [
        {
            "blog": {
                "active": true,
                "can_be_followed": true,
                "name": "izs",
                "share_following": false,
                "share_likes": false,
                "theme": {
                    "avatar_shape": "square",
                    "background_color": "#444444",
                    "body_font": "Helvetica Neue",
                    "header_bounds": "978,2448,2355,0",
                    "header_focus_height": 1152,
                    "header_focus_width": 2048,
                    "header_full_height": 3264,
                    "header_full_width": 2448,
                    "header_image": "https://static.tumblr.com/d248e27715343669f06a3852fd2cda53/utow0jf/nwUnbvgl6/tumblr_static_d2yiqqjdv1w8gsw0s0g4goc0o.jpg",
                    "header_image_focused": "https://static.tumblr.com/d248e27715343669f06a3852fd2cda53/utow0jf/mA1nbvglg/tumblr_static_tumblr_static_d2yiqqjdv1w8gsw0s0g4goc0o_focused_v3.jpg",
                    "header_image_scaled": "https://static.tumblr.com/d248e27715343669f06a3852fd2cda53/utow0jf/nwUnbvgl6/tumblr_static_d2yiqqjdv1w8gsw0s0g4goc0o_2048_v2.jpg",
                    "header_stretch": true,
                    "link_color": "#FB4C16",
                    "show_avatar": true,
                    "show_description": true,
                    "show_header_image": true,
                    "show_title": true,
                    "title_color": "#fb4c16",
                    "title_font": "Gibson",
                    "title_font_weight": "regular"
                }
            },
            "content": "<p><a href=\"https://en.wikipedia.org/wiki/Newcomb%27s_paradox\">Newcomb&rsquo;s Problem</a>\nis a very divisive thought experiment in decision theory. The tl;dr version is:</p>\n\n<p>A supreme intelligence Omega comes down from the sky, and offers you\ntwo boxes, labeled A and B.  In box A, Omega has placed $1000.</p>\n\n<p>Omega makes a prediction about whether you will open only one box, or\nboth boxes.  If Omega predicts that you will open both boxes, then box\nB is empty.  If Omega predicts that you will open only one box, then\nOmega places $1000000 in box B.</p>\n\n<p>In over a million trials, Omega has never incorrectly predicted\nsomeone&rsquo;s decision.  (Supreme intelligence is supreme!)</p>\n\n<p>Omega places both boxes before you, and flies away to torment some\nother decision theorist.</p>\n\n<p>Do you open both boxes, or just box B?</p>\n\n<p>Well, you figure, Omega is gone now, its prediction already in the\npast.  At this point, if I open both boxes, then I&rsquo;ll get either $1000\nor $1001000.  If I open only box B, then I&rsquo;ll get either $0 or\n$1000000.  Regardless of Omega&rsquo;s prediction, I&rsquo;m always better off\nopening both boxes.</p>\n\n<p>So you open box B, and find it empty.</p>\n\n<p>You lament that Omega seemingly rewards &ldquo;improper&rdquo; decision theorists,\nand treat yourself to $1000 worth of whatever.  Since you&rsquo;re a\ndedicated rationalist, you probably make a bunch of sound investments\nwith it and end up doing ok anyway.</p>\n\n<p>Good for you.</p>\n\n<p>Another approach is to commit to opening only box B, and stick to that\ncommitment.  Decision theory be damned, I want a million bucks.\nBefore doing anything else, you set box A on fire, just to be sure.\nYou open box B, and get a million dollars.</p>\n\n<p>What use is a decision theory if it doesn&rsquo;t optimize outcomes?  That&rsquo;s\nnot to say that it&rsquo;s worthless to study the science of priors and\nstatistics and possible outcomes.  Certainly, in most situations, we\nare not dealing with supreme intelligences handing out money\ncapriciously.  But in the real world, there <em>are</em> occasionally\nsituations where the ends matter more than being theoretically\ncorrect.</p>\n\n<p>On the other hand, perhaps a purity of theoretical correctness is an\nimportant part of one&rsquo;s self-image.  Maybe it imparts emotional\nsatisfaction that a million dollars just can&rsquo;t buy.</p>\n\n<p>It&rsquo;s perfectly fine to be a two-boxer.  In a way, I respect it, like a\nmonk or an artist.  There&rsquo;s a beauty in that purity.</p>\n\n<p>But still.  Fuck that, I want the money.  I can be a monk later.</p>\n\n<hr /><p>Most programming languages are to some extent art projects.  There&rsquo;s a\nlot of subjectivity to them.  They exist to seek a beautiful ideal.</p>\n\n<p>Most programming languages are also to some extent practical.  You can\ndo real stuff with them.  They exist to make stuff.</p>\n\n<p>The difference is, when tradeoffs must be made between &ldquo;beautiful\nideal&rdquo; and &ldquo;make stuff&rdquo;, what wins?</p>\n\n<p>If our ideal is in fact beautiful, and if we are skilled in our\npursuit of it, then one might expect that these trade-offs will be\ninfrequent.  The most beautiful programming language is the one that\nis the most pragmatic.</p>\n\n<p>But like boxes of money, programming languages do not exist in a\nvacuum.  We have imperfect vision, and may find ourselves heading down\na blind alley to explore what we hope will be beautiful.  In the\nmaking of things, we may find that it was a mistake, and that the only\nway out is to choose to either make the language more beautiful (and\nlose pragmatic value for its current users) or preserve pragmatic\nvalue (and give up on some potential beauty).</p>\n\n<p>Both choices are fraught with hazard.  The first can alienate the\ncommunity.  The second can lead to a mongrel language with warts and\nbad parts.</p>\n\n<p>Making software is the purpose of a programming language.  That is the\nwinning condition.  Valuing something other than that seems to me akin\nto opening both boxes, because decision theory said so.</p>\n\n<p>In box A, Omega has placed beauty.  In box B, Omega has placed\npragmatism and community, but only if Omega predicts that you will\nonly choose box B.  Omega has never been wrong.</p>\n\n<p>Make your choice.</p>\n\n<p>Except, in this version, you can open B, and get pragmatism and\ncommunity.  But once opened, if you choose A, then the community will\neventually be lost.</p>\n\n<p>I can see the value in a beautiful thing.  But for myself,\nwilly-nilly, I like useful software and happy communities more than\nprogramming languages for their own sake.</p>\n\n<p>This is why I love JavaScript so much.  Fuck beautiful code, I wanna\nmake a web page.  We&rsquo;d rather lack a feature than add something\nthat&rsquo;ll break anything.  We drag the albatross of ancient websites\nalong with us, and while this is often a curse, it is also a sort of\nblessing.</p>\n\n<p>JavaScript is a one-boxer language.</p>",
            "content_raw": "<p><a href=\"https://en.wikipedia.org/wiki/Newcomb%27s_paradox\">Newcomb\u2019s Problem</a>\nis a very divisive thought experiment in decision theory. The tl;dr version is:</p>\n\n<p>A supreme intelligence Omega comes down from the sky, and offers you\ntwo boxes, labeled A and B.  In box A, Omega has placed $1000.</p>\n\n<p>Omega makes a prediction about whether you will open only one box, or\nboth boxes.  If Omega predicts that you will open both boxes, then box\nB is empty.  If Omega predicts that you will open only one box, then\nOmega places $1000000 in box B.</p>\n\n<p>In over a million trials, Omega has never incorrectly predicted\nsomeone\u2019s decision.  (Supreme intelligence is supreme!)</p>\n\n<p>Omega places both boxes before you, and flies away to torment some\nother decision theorist.</p>\n\n<p>Do you open both boxes, or just box B?</p>\n\n<p>Well, you figure, Omega is gone now, its prediction already in the\npast.  At this point, if I open both boxes, then I\u2019ll get either $1000\nor $1001000.  If I open only box B, then I\u2019ll get either $0 or\n$1000000.  Regardless of Omega\u2019s prediction, I\u2019m always better off\nopening both boxes.</p>\n\n<p>So you open box B, and find it empty.</p>\n\n<p>You lament that Omega seemingly rewards \u201cimproper\u201d decision theorists,\nand treat yourself to $1000 worth of whatever.  Since you\u2019re a\ndedicated rationalist, you probably make a bunch of sound investments\nwith it and end up doing ok anyway.</p>\n\n<p>Good for you.</p>\n\n<p>Another approach is to commit to opening only box B, and stick to that\ncommitment.  Decision theory be damned, I want a million bucks.\nBefore doing anything else, you set box A on fire, just to be sure.\nYou open box B, and get a million dollars.</p>\n\n<p>What use is a decision theory if it doesn\u2019t optimize outcomes?  That\u2019s\nnot to say that it\u2019s worthless to study the science of priors and\nstatistics and possible outcomes.  Certainly, in most situations, we\nare not dealing with supreme intelligences handing out money\ncapriciously.  But in the real world, there <em>are</em> occasionally\nsituations where the ends matter more than being theoretically\ncorrect.</p>\n\n<p>On the other hand, perhaps a purity of theoretical correctness is an\nimportant part of one\u2019s self-image.  Maybe it imparts emotional\nsatisfaction that a million dollars just can\u2019t buy.</p>\n\n<p>It\u2019s perfectly fine to be a two-boxer.  In a way, I respect it, like a\nmonk or an artist.  There\u2019s a beauty in that purity.</p>\n\n<p>But still.  Fuck that, I want the money.  I can be a monk later.</p>\n\n<hr><p>Most programming languages are to some extent art projects.  There\u2019s a\nlot of subjectivity to them.  They exist to seek a beautiful ideal.</p>\n\n<p>Most programming languages are also to some extent practical.  You can\ndo real stuff with them.  They exist to make stuff.</p>\n\n<p>The difference is, when tradeoffs must be made between \u201cbeautiful\nideal\u201d and \u201cmake stuff\u201d, what wins?</p>\n\n<p>If our ideal is in fact beautiful, and if we are skilled in our\npursuit of it, then one might expect that these trade-offs will be\ninfrequent.  The most beautiful programming language is the one that\nis the most pragmatic.</p>\n\n<p>But like boxes of money, programming languages do not exist in a\nvacuum.  We have imperfect vision, and may find ourselves heading down\na blind alley to explore what we hope will be beautiful.  In the\nmaking of things, we may find that it was a mistake, and that the only\nway out is to choose to either make the language more beautiful (and\nlose pragmatic value for its current users) or preserve pragmatic\nvalue (and give up on some potential beauty).</p>\n\n<p>Both choices are fraught with hazard.  The first can alienate the\ncommunity.  The second can lead to a mongrel language with warts and\nbad parts.</p>\n\n<p>Making software is the purpose of a programming language.  That is the\nwinning condition.  Valuing something other than that seems to me akin\nto opening both boxes, because decision theory said so.</p>\n\n<p>In box A, Omega has placed beauty.  In box B, Omega has placed\npragmatism and community, but only if Omega predicts that you will\nonly choose box B.  Omega has never been wrong.</p>\n\n<p>Make your choice.</p>\n\n<p>Except, in this version, you can open B, and get pragmatism and\ncommunity.  But once opened, if you choose A, then the community will\neventually be lost.</p>\n\n<p>I can see the value in a beautiful thing.  But for myself,\nwilly-nilly, I like useful software and happy communities more than\nprogramming languages for their own sake.</p>\n\n<p>This is why I love JavaScript so much.  Fuck beautiful code, I wanna\nmake a web page.  We\u2019d rather lack a feature than add something\nthat\u2019ll break anything.  We drag the albatross of ancient websites\nalong with us, and while this is often a curse, it is also a sort of\nblessing.</p>\n\n<p>JavaScript is a one-boxer language.</p>",
            "is_current_item": true,
            "is_root_item": true,
            "post": {
                "id": "150129331398"
            }
        }
    ],
    "type": "text"
}